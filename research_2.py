# -*- coding: utf-8 -*-
"""research 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wDZ0mU-7GmNcNCkDgeZMMRk2EVrwLS0R
"""

pip install tensorflow keras numpy

import os
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.regularizers import l2
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
from google.colab.patches import cv2_imshow

# Directories for training and validation datasets
train_dir = 'train_data/train'
validation_dir = 'valid_data/valid'

# Reading the annotation CSV files
train_annotation = pd.read_csv('/content/train_data/train/_annotations.csv')
valid_annotation = pd.read_csv('/content/valid_data/valid/_annotations.csv')

# Function to load images and labels from annotations
def load_data(annotation_df, base_dir):
    images = []
    labels = []
    missing_files = 0
    for _, row in annotation_df.iterrows():
        img_path = os.path.join(base_dir, row['filename'])
        if os.path.exists(img_path):
            img = load_img(img_path)
            img_array = img_to_array(img)

            # Crop the image using bounding box coordinates
            xmin, ymin, xmax, ymax = int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax'])
            img_cropped = img_array[ymin:ymax, xmin:xmax]
            img_cropped_resized = cv2.resize(img_cropped, (150, 150))

            images.append(img_cropped_resized)
            labels.append(row['class'])
        else:
            print(f"File {img_path} not found.")
            missing_files += 1
    print(f"Total missing files: {missing_files}")
    images = np.array(images)
    labels = np.array(labels)
    return images, labels

# Debugging: Print the first few rows of the annotation DataFrames
print("First few rows of training annotations:")
print(train_annotation.head())

print("First few rows of validation annotations:")
print(valid_annotation.head())

# Loading training data
train_images, train_labels = load_data(train_annotation, train_dir)
valid_images, valid_labels = load_data(valid_annotation, validation_dir)

# Debugging: Check if data is loaded correctly
print(f"Loaded {len(train_images)} training images and {len(train_labels)} training labels.")
print(f"Loaded {len(valid_images)} validation images and {len(valid_labels)} validation labels.")

# If no images or labels are loaded, stop execution
if len(train_images) == 0 or len(train_labels) == 0 or len(valid_images) == 0 or len(valid_labels) == 0:
    raise ValueError("No images or labels were loaded. Please check your file paths and CSV annotations.")

# Normalize the images
train_images = train_images / 255.0
valid_images = valid_images / 255.0

# Encode the labels
label_encoder = LabelEncoder()
train_labels_encoded = label_encoder.fit_transform(train_labels)
valid_labels_encoded = label_encoder.transform(valid_labels)

# One-hot encoding the labels
train_labels = tf.keras.utils.to_categorical(train_labels_encoded)
valid_labels = tf.keras.utils.to_categorical(valid_labels_encoded)

# Data augmentation for training
train_datagen = ImageDataGenerator(
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    brightness_range=[0.5, 1.5]
)

# No data augmentation for validation
validation_datagen = ImageDataGenerator()

# Creating data generators
train_generator = train_datagen.flow(train_images, train_labels, batch_size=32)
validation_generator = validation_datagen.flow(valid_images, valid_labels, batch_size=32)

# Build the CNN model with more regularization
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3), kernel_regularizer=l2(0.001)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.001)),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.001)),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(512, activation='relu', kernel_regularizer=l2(0.001)),
    Dropout(0.5),
    Dense(len(label_encoder.classes_), activation='softmax')
])

# Compile the model
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)

# Train the model
history = model.fit(
    train_generator,
    steps_per_epoch=len(train_generator),
    epochs=30,
    validation_data=validation_generator,
    validation_steps=len(validation_generator),
    callbacks=[early_stopping, model_checkpoint]
)

# Load the best model
best_model = tf.keras.models.load_model('best_model.h5')

# Evaluate the best model
evaluation = best_model.evaluate(validation_generator)
print("Validation Accuracy:", evaluation[1])

# Plot training & validation accuracy values
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

# Plot training & validation loss values
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

# Plot confusion matrix
predictions = best_model.predict(validation_generator)
predicted_classes = np.argmax(predictions, axis=1)
true_classes = np.argmax(valid_labels, axis=1)
class_labels = list(label_encoder.classes_)
conf_matrix = confusion_matrix(true_classes, predicted_classes)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# Function to preprocess each frame
def preprocess_frame(frame):
    frame = cv2.resize(frame, (150, 150))
    frame = frame.astype('float32') / 255
    frame = np.expand_dims(frame, axis=0)
    return frame

# Path to the image
img_path = '/content/download (1).jpg'

# Read and preprocess the image
frame = cv2.imread(img_path)
if frame is not None:
    preprocessed_frame = preprocess_frame(frame)
    prediction = best_model.predict(preprocessed_frame)[0]

    label = class_labels[np.argmax(prediction)]

    cv2.putText(frame, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
    cv2_imshow(frame)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
else:
    print("Error: Image not found or path is incorrect.")